{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96baf527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HCASE Embedding\n",
    "#\n",
    "# Author: Gergely Zahoranszky-Kohalmi, PhD\n",
    "#\n",
    "# Email: gergely.zahoranszky-kohalmi@nih.gov\n",
    "#\n",
    "# Organization: National Center for Advancing Translational Sciences (NCATS/NIH)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6763e98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hcase\n",
    "import pandas as pd\n",
    "from rdkit.rdBase import BlockLogs\n",
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aa07498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config section\n",
    "fname_reference_scaffolds = '../data/scaffolds_chembl_24.tab'\n",
    "fname_structures = '../data/STD_drugbank_approved_structures_v5.txt'\n",
    "fname_out_space = '../data/hc_space.tab'\n",
    "fname_out_embedding = '../data/drugs_emb_hcase_chembl.tab'\n",
    "\n",
    "\n",
    "n_dim = 2\n",
    "use_precomputed_reference_spaces = False\n",
    "do_downsampling = True # TEMP\n",
    "rnd_seed = 55555\n",
    "sample_size = 2000\n",
    "use_cupy = cp.cuda.is_available()\n",
    "batch_size = 500 # if too high out of memory error will occur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0f4f5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets\n",
    "\n",
    "df_ref_scaffolds = pd.read_csv (fname_reference_scaffolds, sep = '\\t')\n",
    "df_structures = pd.read_csv (fname_structures, sep = '\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77925358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean-up datasets\n",
    "\n",
    "df_structures = df_structures.rename (columns = {'Structure': 'structure', 'ID': 'id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02e032bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce datasets for workflow development (optional)\n",
    "\n",
    "if do_downsampling:\n",
    "\n",
    "    df_ref_scaffolds = df_ref_scaffolds.sample (n = sample_size, random_state = rnd_seed)\n",
    "    df_structures = df_structures.sample (n = sample_size, random_state = rnd_seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfba1f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref_scaffolds = df_ref_scaffolds[['pattern_id', 'structure', 'ptype', 'hash']].copy()\n",
    "df_ref_scaffolds = df_ref_scaffolds.query(\"ptype == 'scaffold'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1c857ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with BlockLogs():\n",
    "    if not use_precomputed_reference_spaces:\n",
    "        # Extract NumPy arrays from the DataFrame\n",
    "        structures = df_ref_scaffolds['structure'].values\n",
    "        pattern_ids = df_ref_scaffolds['pattern_id'].values\n",
    "\n",
    "        # Call the NumPy-based function\n",
    "        structures, order, scaffold_ids, scaffold_keys = hcase.order_scaffolds_np(structures, pattern_ids)\n",
    "\n",
    "        # Convert the NumPy arrays back into a DataFrame for interpretability\n",
    "        df_hcase_space = pd.DataFrame({\n",
    "            'structure': structures,\n",
    "            'order': order,\n",
    "            'scaffold_id': scaffold_ids,\n",
    "            'scaffold_key': scaffold_keys\n",
    "        })\n",
    "\n",
    "        # Save to CSV\n",
    "        df_hcase_space.to_csv(fname_out_space, sep='\\t', index=False)\n",
    "\n",
    "    else:\n",
    "        # Load precomputed scaffold space\n",
    "        df_hcase_space = pd.read_csv(fname_out_space, sep='\\t')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad252027",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ref_fingerprints = df_hcase_space['scaffold_key'].values\n",
    "structures = df_structures['structure'].values\n",
    "ids = df_structures['id'].values\n",
    "df_space_order = df_hcase_space['order'].values  # The order column from df_space as a NumPy array\n",
    "\n",
    "with BlockLogs():\n",
    "    embedded_data = hcase.embed(ref_fingerprints, structures, ids, n_dim, df_space_order, use_cupy=use_cupy, batch_size=batch_size)\n",
    "\n",
    "    df_embedded_final = pd.DataFrame(embedded_data, columns=['id', 'structure', 'scaffold_key', 'sk_struct', 'closest_order', 'bucket_id'] + [f\"Dim_{i+1}\" for i in range(n_dim)])\n",
    "\n",
    "    df_embedded_final.to_csv(fname_out_embedding, sep='\\t', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cupy-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
